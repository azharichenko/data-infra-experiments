{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2048 RL\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import game_gym\n",
    "from game_gym.envs import GameEnv\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make(\"2048-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "moves = {\n",
    "    0: \"Up\",\n",
    "    1: \"Down\",\n",
    "    2: \"Left\",\n",
    "    3: \"Right\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "[2, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 4, 0, 0]\n",
      "\n",
      "####################\n",
      "[4, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[2, 4, 0, 0]\n",
      "\n",
      "Down\n",
      "####################\n",
      "[0, 0, 0, 4]\n",
      "[0, 2, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 2, 4]\n",
      "\n",
      "Right\n",
      "####################\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[4, 0, 0, 0]\n",
      "[0, 2, 2, 8]\n",
      "\n",
      "Down\n",
      "####################\n",
      "[4, 2, 2, 8]\n",
      "[0, 0, 2, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "\n",
      "Up\n",
      "####################\n",
      "[0, 0, 8, 8]\n",
      "[0, 0, 0, 2]\n",
      "[0, 2, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "\n",
      "Right\n",
      "####################\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 2, 8]\n",
      "[0, 2, 8, 2]\n",
      "\n",
      "Down\n",
      "####################\n",
      "[0, 0, 0, 2]\n",
      "[0, 0, 0, 0]\n",
      "[2, 8, 0, 0]\n",
      "[2, 8, 2, 0]\n",
      "\n",
      "Left\n",
      "####################\n",
      "[4, 16, 2, 2]\n",
      "[0, 0, 0, 0]\n",
      "[0, 2, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "\n",
      "Up\n",
      "####################\n",
      "[0, 4, 16, 4]\n",
      "[2, 0, 0, 0]\n",
      "[0, 0, 0, 2]\n",
      "[0, 0, 0, 0]\n",
      "\n",
      "Right\n",
      "####################\n",
      "[0, 4, 16, 4]\n",
      "[0, 0, 0, 2]\n",
      "[0, 0, 0, 2]\n",
      "[0, 0, 0, 4]\n",
      "\n",
      "Right\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()\n",
    "\n",
    "for _ in range(10):\n",
    "    action = np.random.randint(4)\n",
    "    env.step(action)\n",
    "    env.render()\n",
    "    print(moves[action])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-05 11:02:08,957\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2020-11-05 11:02:14,138\tERROR syncer.py:63 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/31.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/16 CPUs, 0/1 GPUs, 0.0/10.79 GiB heap, 0.0/3.71 GiB objects<br>Result logdir: C:\\Users\\Alex\\Projects\\2048-rl\\PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_GameEnv_451fd_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-05 11:02:17,276\tERROR trial_runner.py:567 -- Trial PPO_GameEnv_451fd_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\tune\\trial_runner.py\", line 515, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\tune\\ray_trial_executor.py\", line 488, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\worker.py\", line 1428, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ImportError): \u001b[36mray::PPO.train()\u001b[39m (pid=37580, ip=192.168.1.21)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 445, in ray._raylet.execute_task\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\worker.py\", line 174, in reraise_actor_init_error\n",
      "    raise self.actor_init_error\n",
      "  File \"python\\ray\\_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 483, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\function_manager.py\", line 553, in actor_method_executor\n",
      "    return method(actor, *args, **kwargs)\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\rllib\\agents\\trainer_template.py\", line 101, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\rllib\\agents\\trainer.py\", line 476, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\tune\\trainable.py\", line 249, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\rllib\\agents\\trainer.py\", line 629, in setup\n",
      "    self._init(self.config, self.env_creator)\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\rllib\\agents\\trainer_template.py\", line 123, in _init\n",
      "    self.workers = self._make_workers(env_creator, self._policy_class,\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\rllib\\agents\\trainer.py\", line 694, in _make_workers\n",
      "    return WorkerSet(\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py\", line 72, in __init__\n",
      "    self._local_worker = self._make_worker(RolloutWorker, env_creator,\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py\", line 268, in _make_worker\n",
      "    worker = cls(\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 418, in __init__\n",
      "    self.policy_map, self.preprocessors = self._build_policy_map(\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1010, in _build_policy_map\n",
      "    policy_map[name] = cls(obs_space, act_space, merged_conf)\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\rllib\\policy\\torch_policy_template.py\", line 202, in __init__\n",
      "    self.model = ModelCatalog.get_model_v2(\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\rllib\\models\\catalog.py\", line 413, in get_model_v2\n",
      "    return wrapper(obs_space, action_space, num_outputs, model_config,\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\rllib\\models\\torch\\fcnet.py\", line 22, in __init__\n",
      "    nn.Module.__init__(self)\n",
      "  File \"c:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\rllib\\utils\\framework.py\", line 128, in __init__\n",
      "    raise ImportError(\"Could not import `torch`.\")\n",
      "ImportError: Could not import `torch`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/31.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/10.79 GiB heap, 0.0/3.71 GiB objects<br>Result logdir: C:\\Users\\Alex\\Projects\\2048-rl\\PPO<br>Number of trials: 1 (1 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_GameEnv_451fd_00000</td><td>ERROR   </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_GameEnv_451fd_00000</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\Alex\\Projects\\2048-rl\\PPO\\PPO_GameEnv_451fd_00000_0_2020-11-05_11-02-14\\error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m 2020-11-05 11:02:17,236\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2020-11-05 11:02:17,403\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffbdff035801000000.\n",
      "2020-11-05 11:02:17,406\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffa97540c201000000.\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [PPO_GameEnv_451fd_00000])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ede02395d858>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# from ray.rllib.agents.a3c.a3c import A3CTrainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPPOTrainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtune\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPPOTrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"env\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mGameEnv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"framework\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"torch\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"num_workers\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"num_envs_per_worker\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"timesteps_total\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m50000\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_at_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\alex\\.virtualenvs\\2048-rl-ludppm6q\\lib\\site-packages\\ray\\tune\\tune.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, loggers, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Trials did not complete\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Trials did not complete: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTuneError\u001b[0m: ('Trials did not complete', [PPO_GameEnv_451fd_00000])"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "# from ray.rllib.agents.a3c.a3c import A3CTrainer  \n",
    "from ray.rllib.agents.ppo.ppo import PPOTrainer\n",
    "tune.run(PPOTrainer, config={\"env\": GameEnv, \"framework\": \"torch\", \"num_workers\": 2, \"num_envs_per_worker\": 10}, stop={\"timesteps_total\": 50000}, checkpoint_at_end=True, local_dir=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
